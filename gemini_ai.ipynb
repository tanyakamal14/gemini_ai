{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyakamal14/gemini_ai/blob/main/gemini_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qjcWFrEuc7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f6b637-4079-4ef9-d876-57824c8f5d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m112.6/155.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIYidrgpD-ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "NLFLgPqpvZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "txL-TniiwWSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=\"AIzaSyCABehd5i4c2W1ZfO07fDcE6d2o-7F4uBo \"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "9HKcsnbNwhhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "ans=model1.generate_content(\"what is gemini ai?\")\n",
        "to_markdown(ans.text)\n"
      ],
      "metadata": {
        "id": "Jrg9qPlgw2gT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "77f2bba8-d894-4da4-fbf4-ba6e9c60dc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Gemini is Google's most capable and general AI model yet, designed to be multimodal from the ground up. Here's a breakdown of what that means:\n> \n> **Key Characteristics of Gemini AI:**\n> \n> *   **Multimodal Native:** Unlike some models that are primarily text-based and then adapted to other modalities, Gemini is designed to understand and reason across different types of information including text, code, audio, image, and video. This means it can seamlessly process and combine these different inputs.\n> \n> *   **Highly Capable:** Gemini achieves state-of-the-art performance on a variety of benchmarks. This suggests a very high level of reasoning, understanding, and problem-solving ability.\n> \n> *   **Three Sizes:** Gemini comes in three versions:\n>     *   **Gemini Ultra:** The largest and most capable model, designed for highly complex tasks.\n>     *   **Gemini Pro:** The best model for scaling across a wide range of tasks.\n>     *   **Gemini Nano:** The most efficient model for on-device tasks.\n> \n> *   **Optimized for Different Platforms:** The different sizes of Gemini allow it to be deployed in various environments, from large data centers to mobile devices.\n> \n> **What Gemini Can Do:**\n> \n> *   **Advanced Reasoning:** Gemini excels at understanding complex concepts and making logical deductions.\n> *   **Creative Content Generation:** It can generate creative content formats, like poems, code, scripts, musical pieces, email, letters, etc.\n> *   **Image and Video Understanding:** It can analyze and interpret images and videos, enabling capabilities like object recognition, scene understanding, and video summarization.\n> *   **Code Generation and Understanding:** Gemini has strong coding capabilities, able to generate, understand, and explain code in various programming languages.\n> *   **Natural Language Processing:** It excels at natural language tasks such as translation, summarization, question answering, and sentiment analysis.\n> *   **Problem Solving:** It can tackle complex problems by combining information from different sources and applying reasoning skills.\n> *   **Integration with Google Products:** Gemini is being integrated into various Google products and services to enhance their capabilities.\n> \n> **Use Cases:**\n> \n> *   **Improved Search:** Gemini could lead to more accurate and relevant search results.\n> *   **Enhanced Productivity Tools:** Integration into Google Workspace (Gmail, Docs, etc.) could offer features like automated summarization, content generation, and improved collaboration.\n> *   **More Intelligent Assistants:** Gemini could power more sophisticated virtual assistants that can understand and respond to complex requests.\n> *   **Advanced Image and Video Analysis:**  Applications in areas like medical imaging, autonomous driving, and security.\n> *   **Code Development:** Assisting developers with code generation, debugging, and optimization.\n> \n> **In summary, Gemini AI represents a significant step forward in AI capabilities due to its multimodal nature, high performance, and adaptability to different platforms. It has the potential to transform a wide range of applications and industries.**\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IMG20240830073336.Image\n",
        "\n",
        "# Replace 'actual/path/to/your/image/download.jpeg' with the actual path to your image file.\n",
        "image_path = \"C:\\Users\\tanya\\OneDrive\\Pictures\\Screenshots\\Screenshot 2025-03-13 123257.png\"  # Example: 'images/my_image.jpg'\n",
        "Image = IMG20240830073336(image_path)\n",
        "Image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "HP-rGpNBGepZ",
        "outputId": "e3819584-e94b-4ba0-a6fe-e888968c6ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-7-52ecbbabd989>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-52ecbbabd989>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    image_path = \"C:\\Users\\tanya\\OneDrive\\Pictures\\Screenshots\\Screenshot 2025-03-13 123257.png\"  # Example: 'images/my_image.jpg'\u001b[0m\n\u001b[0m                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for m in genai.list_models():\n",
        "#   if 'generateContent' in m.supported_generation_methods:\n",
        "#     print(m.name)"
      ],
      "metadata": {
        "id": "ftz-Pr1f3o5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "ZdQkYYtzzFe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(img)\n",
        "\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "WHHULo9MzRh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"solve this math problem step by step in hindi\", img], stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "d5uHqfGvzX5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "g_DGOSYxzfil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}